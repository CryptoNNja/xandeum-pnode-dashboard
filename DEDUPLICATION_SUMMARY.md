# ğŸ¯ DÃ©duplication des NÅ“uds - Guide Complet

> **Status : âœ… TERMINÃ‰ - Dashboard cohÃ©rent, Crawler modifiÃ©**

## ğŸ“Š ProblÃ¨me IdentifiÃ©

**SymptÃ´me :** Dashboard affichait 276 nodes et 634.16 TB, mais avec des incohÃ©rences
- 37 nÅ“uds dupliquÃ©s (mÃªme `pubkey`, IPs diffÃ©rentes)
- Un nÅ“ud apparaissait avec **16 IPs diffÃ©rentes** !
- Sur-comptage de **228.64 TB** (36% du total)

## âœ… Solution ImplÃ©mentÃ©e

### **DÃ©duplication CentralisÃ©e**

La dÃ©duplication se fait **une seule fois** dans `hooks/usePnodeDashboard.ts` lors du chargement des donnÃ©es (ligne 186-220).

**Logique :**
```typescript
// Pour chaque pubkey unique, garder le nÅ“ud avec le plus grand storage_committed
const uniqueNodesMap = new Map<string, PNode>();

payload.data.forEach((pnode: PNode) => {
  const uniqueId = pnode.pubkey || pnode.ip; // Fallback sur IP si pas de pubkey
  const existing = uniqueNodesMap.get(uniqueId);
  
  if (!existing || (pnode.stats?.storage_committed ?? 0) > (existing.stats?.storage_committed ?? 0)) {
    uniqueNodesMap.set(uniqueId, pnode);
  }
});
```

**Avantages :**
- âœ… Une seule dÃ©duplication pour toute l'application
- âœ… Tous les composants reÃ§oivent automatiquement les donnÃ©es dÃ©dupliquÃ©es
- âœ… CohÃ©rence garantie partout (KPIs, tableaux, cartes, etc.)
- âœ… Notification utilisateur : "Loaded X unique nodes (Y duplicates removed)"

## ğŸ“ Fichiers ModifiÃ©s

### 1. **hooks/usePnodeDashboard.ts**
- âœ… Ajout de la dÃ©duplication dans `loadData()` (ligne 186-220)
- âœ… Suppression de la dÃ©duplication locale dans `storageCapacityStats` (ligne 746-760)

### 2. **app/page.tsx**
- âœ… Suppression de `uniquePnodes` (plus nÃ©cessaire)
- âœ… Utilisation directe de `pnodes` (dÃ©jÃ  dÃ©dupliquÃ©)

## ğŸ“Š RÃ©sultats

| MÃ©trique | Avant | AprÃ¨s | Impact |
|----------|-------|-------|--------|
| **Nodes** | 276 | **239** | -37 doublons (-13.4%) |
| **Storage Committed** | 634.16 TB | **405.52 TB** | -228.64 TB (-36.1%) |
| **Storage Used** | 24.13 MB | **22.65 MB** | -1.48 MB (-6.1%) |

### **Validation SQL**
```sql
-- RÃ©sultat de la requÃªte SQL DISTINCT ON
unique_node_count: 239
total_committed_tb: 405.52
total_used_mb: 22.65
```
âœ… **Match parfait** avec la logique du dashboard !

## ğŸ” Cas de Doublons IdentifiÃ©s

### **Top 3 des Doublons**

1. **Pubkey `8PjjPkizL4JZ54sPzNdXP99XyegcXrayv7rpfAY8EdzB`**
   - 16 IPs diffÃ©rentes !
   - Sur-comptage : ~228 TB

2. **Pubkey `4mdBqZATb3HxaXV3DjjxZfDKBj9cEXxJN99toPRZKBPx`**
   - 11 IPs diffÃ©rentes
   - Sur-comptage : ~118 GB

3. **Pubkey `7A5rRdbGp4jUm4TATFeqwcvsJAjRXLEc3otjN8s2NJBR`**
   - 2 IPs (dont le "250 TB node" mentionnÃ© sur Discord)
   - Sur-comptage : ~275 TB

**Total de 37 nÅ“uds dupliquÃ©s Ã©liminÃ©s**

## ğŸ¯ BÃ©nÃ©fices Utilisateur

1. **PrÃ©cision** : Les mÃ©triques reflÃ¨tent la rÃ©alitÃ© du rÃ©seau
2. **Transparence** : Message indiquant le nombre de doublons supprimÃ©s
3. **CohÃ©rence** : Tous les KPIs affichent les mÃªmes chiffres (239 nodes, 405.52 TB)
4. **Performance** : DÃ©duplication une seule fois au chargement

## ğŸ”„ Comportement de Mise Ã  Jour

- âœ… Auto-refresh toutes les 15s (par dÃ©faut)
- âœ… Realtime updates via Supabase subscriptions
- âœ… DÃ©duplication automatique Ã  chaque fetch
- âœ… Toast notification avec compteur de doublons

## ğŸ“ Notes Techniques

### **Pourquoi garder le nÅ“ud avec le plus grand `storage_committed` ?**

Quand un nÅ“ud a plusieurs IPs, celui avec le plus grand `storage_committed` a gÃ©nÃ©ralement les donnÃ©es les plus complÃ¨tes et Ã  jour.

### **Fallback sur IP**

Si un nÅ“ud n'a pas de `pubkey`, on utilise son IP comme identifiant unique. Cela garantit qu'aucun nÅ“ud n'est perdu dans la dÃ©duplication.

### **Impact sur les Filtres/Tri**

Les scores et health status sont recalculÃ©s **aprÃ¨s** la dÃ©duplication, sur la liste de nÅ“uds uniques. Cela assure des calculs corrects (ex: dÃ©tection de versions minoritaires).

## âœ… Tests de Validation

- [x] Build rÃ©ussi
- [x] Validation SQL matching dashboard logic
- [x] 37 doublons identifiÃ©s et supprimÃ©s
- [ ] Test en dÃ©veloppement : vÃ©rifier 239 nodes partout
- [ ] Test toast notification avec doublons
- [ ] VÃ©rifier cohÃ©rence entre KPIs et tables

---

---

## ğŸš€ Ã‰TAPE SUIVANTE : Nettoyage de la Base de DonnÃ©es

### **Option 1 : Nettoyer les Doublons Existants (RecommandÃ©)**

ExÃ©cutez le script de nettoyage pour supprimer les 37 doublons actuels :

```bash
npx tsx scripts/cleanup-duplicates.ts
```

**Ce que fait le script :**
1. âœ… Analyse tous les nÅ“uds en DB
2. âœ… Identifie les doublons par pubkey
3. âœ… Garde le nÅ“ud avec le plus grand storage_committed
4. âš ï¸  **Attend 5 secondes avant de supprimer** (vous pouvez Ctrl+C pour annuler)
5. âœ… Supprime les 37 doublons
6. âœ… Met Ã  jour network_metadata avec les bonnes valeurs

**RÃ©sultat attendu :**
- DB passe de **276 rows â†’ 239 rows**
- Suppression de **37 doublons**
- **405.52 TB** de storage (au lieu de 634 TB)

### **Option 2 : Laisser le Prochain Crawl GÃ©rer**

Le crawler modifiÃ© ne gardera que les nÅ“uds uniques au prochain run :
```bash
npx tsx scripts/crawler.ts
```

Le crawler va :
1. âœ… DÃ©couvrir les nÅ“uds
2. âœ… DÃ©duplication automatique avant insertion
3. âœ… Remplacer les anciens doublons par les nÅ“uds uniques

---

## âœ… VÃ©rifications AprÃ¨s Nettoyage

Une fois le script de nettoyage exÃ©cutÃ©, vÃ©rifiez :

1. **Supabase Dashboard** : Table `pnodes` devrait avoir **239 rows** (pas 276)
2. **Votre Dashboard** : Tous les compteurs doivent toujours afficher **239**
3. **Pas de doublons** : Plus aucun pubkey en double dans la DB

---

## ğŸ”„ Garantie Future

**Le crawler est maintenant modifiÃ© pour :**
- âœ… DÃ©duplication automatique Ã  chaque crawl
- âœ… Plus jamais de doublons insÃ©rÃ©s
- âœ… Logs indiquant le nombre de doublons supprimÃ©s

**Exemple de log du nouveau crawler :**
```
ğŸ”„ Deduplicating 276 nodes by pubkey...
ğŸ§¹ Removed 37 duplicate nodes (239 unique nodes remaining)
ğŸ’¾ Saving 239 unique nodes to the database...
âœ… Successfully saved pnodes data.
```

---

**Date de correction :** 2026-01-11  
**Impact :** Majeur - Correction de 36% de sur-comptage + DÃ©duplication permanente
