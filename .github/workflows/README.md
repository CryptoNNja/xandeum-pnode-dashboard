# GitHub Actions - Xandeum pNodes Crawler

## ğŸ“‹ Configuration

This workflow automatically runs the Xandeum crawler every **10 minutes**.

### ğŸ” Required Secrets

Add these secrets to your GitHub repository:

1. **Settings** â†’ **Secrets and variables** â†’ **Actions** â†’ **New repository secret**

2. Add these 2 secrets:

| Name | Value | Description |
|------|-------|-------------|
| `SUPABASE_URL` | `https://xxx.supabase.co` | Your Supabase project URL |
| `SUPABASE_ANON_KEY` | `eyJhbGc...` | Supabase public (anon) key |

### â±ï¸ Cron Frequency

**Current:** Every 10 minutes (`*/10 * * * *`)

**To change the frequency:**

```yaml
# Every 5 minutes
- cron: '*/5 * * * *'

# Every 15 minutes
- cron: '*/15 * * * *'

# Every hour
- cron: '0 * * * *'
```

### ğŸš€ Manual Trigger

You can run the crawler manually:

1. Go to **Actions** in GitHub
2. Click on **Xandeum pNodes Crawler**
3. Click **Run workflow** â†’ **Run workflow**

### ğŸ“Š View Logs

1. **Actions** â†’ Click on a run
2. Click on **crawl** job
3. Click on **Run pNodes crawler** step

You will see:
```
ğŸš€ Starting Xandeum pNodes crawler...
ğŸ“¡ Discovering pNodes...
âœ… Metadata discovery complete. Found X versions and Y pubkeys.
ğŸ’¾ Upserting XX pnodes to Supabase...
âœ… Successfully upserted XX pnodes
âœ… Crawler completed successfully!
```

### ğŸ’° Cost

**100% FREE** on GitHub Actions (2000 minutes/month included)

- 1 run = ~2-3 minutes
- 6 runs/hour Ã— 24h Ã— 30d = ~12,960 minutes/month
- **Well within the free tier!**

### âš ï¸ Limits

- **Timeout:** 10 minutes max per run
- If the crawler takes more than 10 min, optimize it or increase the timeout

### ğŸ”§ Troubleshooting

**"Secrets not found" error:**
- Verify that you've added `SUPABASE_URL` and `SUPABASE_ANON_KEY` in GitHub secrets

**"npm ci failed" error:**
- Verify that your `package-lock.json` is up to date
- Commit and push changes

**Crawler timeout:**
- Increase `timeout-minutes: 15` in the workflow
- Or optimize the crawler to run faster
