# GitHub Actions - Xandeum pNodes Crawler

## ğŸ“‹ Configuration

Ce workflow exÃ©cute automatiquement le crawler Xandeum toutes les **10 minutes**.

### ğŸ” Secrets requis

Ajoute ces secrets dans ton repo GitHub :

1. **Settings** â†’ **Secrets and variables** â†’ **Actions** â†’ **New repository secret**

2. Ajoute ces 2 secrets :

| Nom | Valeur | Description |
|-----|--------|-------------|
| `SUPABASE_URL` | `https://xxx.supabase.co` | URL de ton projet Supabase |
| `SUPABASE_ANON_KEY` | `eyJhbGc...` | ClÃ© publique (anon) de Supabase |

### â±ï¸ FrÃ©quence du cron

**Actuel :** Toutes les 10 minutes (`*/10 * * * *`)

**Pour changer la frÃ©quence :**

```yaml
# Toutes les 5 minutes
- cron: '*/5 * * * *'

# Toutes les 15 minutes
- cron: '*/15 * * * *'

# Toutes les heures
- cron: '0 * * * *'
```

### ğŸš€ Lancement manuel

Tu peux lancer le crawler manuellement :

1. Va sur **Actions** dans GitHub
2. Clique sur **Xandeum pNodes Crawler**
3. Clique **Run workflow** â†’ **Run workflow**

### ğŸ“Š Voir les logs

1. **Actions** â†’ Clique sur un run
2. Clique sur **crawl** job
3. Clique sur **Run pNodes crawler** step

Tu verras :
```
ğŸš€ Starting Xandeum pNodes crawler...
ğŸ“¡ Discovering pNodes...
âœ… Metadata discovery complete. Found X versions and Y pubkeys.
ğŸ’¾ Upserting XX pnodes to Supabase...
âœ… Successfully upserted XX pnodes
âœ… Crawler completed successfully!
```

### ğŸ’° CoÃ»t

**100% GRATUIT** sur GitHub Actions (2000 minutes/mois incluses)

- 1 run = ~2-3 minutes
- 6 runs/heure Ã— 24h Ã— 30j = ~12,960 minutes/mois
- **Largement dans la limite gratuite !**

### âš ï¸ Limites

- **Timeout :** 10 minutes max par run
- Si le crawler prend plus de 10 min, optimise-le ou augmente le timeout

### ğŸ”§ Troubleshooting

**Erreur "Secrets not found" :**
- VÃ©rifie que tu as bien ajoutÃ© `SUPABASE_URL` et `SUPABASE_ANON_KEY` dans les secrets GitHub

**Erreur "npm ci failed" :**
- VÃ©rifie que ton `package-lock.json` est Ã  jour
- Commit et push les changements

**Crawler timeout :**
- Augmente `timeout-minutes: 15` dans le workflow
- Ou optimise le crawler pour aller plus vite
